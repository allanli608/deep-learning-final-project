{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1500,
  "global_step": 16968,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017681902572716825,
      "grad_norm": 2.845956325531006,
      "learning_rate": 1.9883309759547384e-05,
      "loss": 1.603,
      "step": 100
    },
    {
      "epoch": 0.03536380514543365,
      "grad_norm": 1.5777395963668823,
      "learning_rate": 1.9765440829797265e-05,
      "loss": 0.4745,
      "step": 200
    },
    {
      "epoch": 0.053045707718150474,
      "grad_norm": 1.8550952672958374,
      "learning_rate": 1.964757190004715e-05,
      "loss": 0.4319,
      "step": 300
    },
    {
      "epoch": 0.0707276102908673,
      "grad_norm": 1.6663739681243896,
      "learning_rate": 1.952970297029703e-05,
      "loss": 0.4228,
      "step": 400
    },
    {
      "epoch": 0.08840951286358412,
      "grad_norm": 1.8840104341506958,
      "learning_rate": 1.9411834040546914e-05,
      "loss": 0.3914,
      "step": 500
    },
    {
      "epoch": 0.10609141543630095,
      "grad_norm": 1.3071304559707642,
      "learning_rate": 1.9293965110796795e-05,
      "loss": 0.3839,
      "step": 600
    },
    {
      "epoch": 0.12377331800901777,
      "grad_norm": 2.016453266143799,
      "learning_rate": 1.917609618104668e-05,
      "loss": 0.3835,
      "step": 700
    },
    {
      "epoch": 0.1414552205817346,
      "grad_norm": 1.599095344543457,
      "learning_rate": 1.905822725129656e-05,
      "loss": 0.3815,
      "step": 800
    },
    {
      "epoch": 0.15913712315445142,
      "grad_norm": 1.7460649013519287,
      "learning_rate": 1.894035832154644e-05,
      "loss": 0.3786,
      "step": 900
    },
    {
      "epoch": 0.17681902572716823,
      "grad_norm": 1.1536914110183716,
      "learning_rate": 1.8822489391796324e-05,
      "loss": 0.3813,
      "step": 1000
    },
    {
      "epoch": 0.19450092829988508,
      "grad_norm": 1.1910406351089478,
      "learning_rate": 1.8704620462046205e-05,
      "loss": 0.3639,
      "step": 1100
    },
    {
      "epoch": 0.2121828308726019,
      "grad_norm": 1.1864972114562988,
      "learning_rate": 1.858675153229609e-05,
      "loss": 0.3656,
      "step": 1200
    },
    {
      "epoch": 0.22986473344531871,
      "grad_norm": 1.1879092454910278,
      "learning_rate": 1.846888260254597e-05,
      "loss": 0.3738,
      "step": 1300
    },
    {
      "epoch": 0.24754663601803553,
      "grad_norm": 1.261845588684082,
      "learning_rate": 1.835101367279585e-05,
      "loss": 0.3652,
      "step": 1400
    },
    {
      "epoch": 0.26522853859075235,
      "grad_norm": 1.738092303276062,
      "learning_rate": 1.8233144743045735e-05,
      "loss": 0.3707,
      "step": 1500
    },
    {
      "epoch": 0.26522853859075235,
      "eval_loss": 0.3535122275352478,
      "eval_runtime": 71.8492,
      "eval_samples_per_second": 157.427,
      "eval_steps_per_second": 19.68,
      "step": 1500
    },
    {
      "epoch": 0.2829104411634692,
      "grad_norm": 0.9316204786300659,
      "learning_rate": 1.8115275813295616e-05,
      "loss": 0.3589,
      "step": 1600
    },
    {
      "epoch": 0.30059234373618604,
      "grad_norm": 1.4341142177581787,
      "learning_rate": 1.79974068835455e-05,
      "loss": 0.3646,
      "step": 1700
    },
    {
      "epoch": 0.31827424630890283,
      "grad_norm": 1.9699040651321411,
      "learning_rate": 1.787953795379538e-05,
      "loss": 0.3674,
      "step": 1800
    },
    {
      "epoch": 0.3359561488816197,
      "grad_norm": 1.2521064281463623,
      "learning_rate": 1.776166902404526e-05,
      "loss": 0.3636,
      "step": 1900
    },
    {
      "epoch": 0.35363805145433647,
      "grad_norm": 1.728308081626892,
      "learning_rate": 1.7643800094295145e-05,
      "loss": 0.3534,
      "step": 2000
    },
    {
      "epoch": 0.3713199540270533,
      "grad_norm": 1.3320558071136475,
      "learning_rate": 1.7525931164545026e-05,
      "loss": 0.3526,
      "step": 2100
    },
    {
      "epoch": 0.38900185659977016,
      "grad_norm": 1.0195857286453247,
      "learning_rate": 1.740806223479491e-05,
      "loss": 0.3483,
      "step": 2200
    },
    {
      "epoch": 0.40668375917248695,
      "grad_norm": 1.3290959596633911,
      "learning_rate": 1.729019330504479e-05,
      "loss": 0.3626,
      "step": 2300
    },
    {
      "epoch": 0.4243656617452038,
      "grad_norm": 1.4056538343429565,
      "learning_rate": 1.717232437529467e-05,
      "loss": 0.3561,
      "step": 2400
    },
    {
      "epoch": 0.4420475643179206,
      "grad_norm": 1.1065669059753418,
      "learning_rate": 1.7054455445544556e-05,
      "loss": 0.3554,
      "step": 2500
    },
    {
      "epoch": 0.45972946689063743,
      "grad_norm": 2.1019606590270996,
      "learning_rate": 1.6936586515794437e-05,
      "loss": 0.3454,
      "step": 2600
    },
    {
      "epoch": 0.4774113694633543,
      "grad_norm": 1.1144607067108154,
      "learning_rate": 1.681871758604432e-05,
      "loss": 0.3547,
      "step": 2700
    },
    {
      "epoch": 0.49509327203607106,
      "grad_norm": 0.9692931771278381,
      "learning_rate": 1.67008486562942e-05,
      "loss": 0.3594,
      "step": 2800
    },
    {
      "epoch": 0.5127751746087879,
      "grad_norm": 1.4781118631362915,
      "learning_rate": 1.6582979726544085e-05,
      "loss": 0.3496,
      "step": 2900
    },
    {
      "epoch": 0.5304570771815047,
      "grad_norm": 1.1463490724563599,
      "learning_rate": 1.6465110796793966e-05,
      "loss": 0.3495,
      "step": 3000
    },
    {
      "epoch": 0.5304570771815047,
      "eval_loss": 0.3391903340816498,
      "eval_runtime": 72.1124,
      "eval_samples_per_second": 156.852,
      "eval_steps_per_second": 19.608,
      "step": 3000
    },
    {
      "epoch": 0.5481389797542215,
      "grad_norm": 1.2093148231506348,
      "learning_rate": 1.6347241867043847e-05,
      "loss": 0.3382,
      "step": 3100
    },
    {
      "epoch": 0.5658208823269384,
      "grad_norm": 1.0060105323791504,
      "learning_rate": 1.622937293729373e-05,
      "loss": 0.3526,
      "step": 3200
    },
    {
      "epoch": 0.5835027848996552,
      "grad_norm": 1.352325677871704,
      "learning_rate": 1.6111504007543612e-05,
      "loss": 0.3543,
      "step": 3300
    },
    {
      "epoch": 0.6011846874723721,
      "grad_norm": 0.8576585054397583,
      "learning_rate": 1.5993635077793496e-05,
      "loss": 0.3375,
      "step": 3400
    },
    {
      "epoch": 0.6188665900450888,
      "grad_norm": 1.5845482349395752,
      "learning_rate": 1.5875766148043377e-05,
      "loss": 0.3449,
      "step": 3500
    },
    {
      "epoch": 0.6365484926178057,
      "grad_norm": 1.4991477727890015,
      "learning_rate": 1.5757897218293257e-05,
      "loss": 0.3408,
      "step": 3600
    },
    {
      "epoch": 0.6542303951905225,
      "grad_norm": 1.0081020593643188,
      "learning_rate": 1.564002828854314e-05,
      "loss": 0.3378,
      "step": 3700
    },
    {
      "epoch": 0.6719122977632394,
      "grad_norm": 1.088545322418213,
      "learning_rate": 1.5522159358793022e-05,
      "loss": 0.3395,
      "step": 3800
    },
    {
      "epoch": 0.6895942003359562,
      "grad_norm": 1.1554580926895142,
      "learning_rate": 1.5404290429042906e-05,
      "loss": 0.3311,
      "step": 3900
    },
    {
      "epoch": 0.7072761029086729,
      "grad_norm": 1.1306062936782837,
      "learning_rate": 1.5286421499292787e-05,
      "loss": 0.3386,
      "step": 4000
    },
    {
      "epoch": 0.7249580054813898,
      "grad_norm": 1.0263595581054688,
      "learning_rate": 1.516855256954267e-05,
      "loss": 0.3456,
      "step": 4100
    },
    {
      "epoch": 0.7426399080541066,
      "grad_norm": 1.0056297779083252,
      "learning_rate": 1.5050683639792552e-05,
      "loss": 0.323,
      "step": 4200
    },
    {
      "epoch": 0.7603218106268235,
      "grad_norm": 1.1446388959884644,
      "learning_rate": 1.4932814710042434e-05,
      "loss": 0.3418,
      "step": 4300
    },
    {
      "epoch": 0.7780037131995403,
      "grad_norm": 1.0092531442642212,
      "learning_rate": 1.4814945780292315e-05,
      "loss": 0.3454,
      "step": 4400
    },
    {
      "epoch": 0.795685615772257,
      "grad_norm": 1.4753122329711914,
      "learning_rate": 1.4697076850542198e-05,
      "loss": 0.3403,
      "step": 4500
    },
    {
      "epoch": 0.795685615772257,
      "eval_loss": 0.32825109362602234,
      "eval_runtime": 71.9288,
      "eval_samples_per_second": 157.253,
      "eval_steps_per_second": 19.658,
      "step": 4500
    },
    {
      "epoch": 0.8133675183449739,
      "grad_norm": 0.9252445101737976,
      "learning_rate": 1.457920792079208e-05,
      "loss": 0.322,
      "step": 4600
    },
    {
      "epoch": 0.8310494209176907,
      "grad_norm": 1.1027019023895264,
      "learning_rate": 1.4461338991041962e-05,
      "loss": 0.3441,
      "step": 4700
    },
    {
      "epoch": 0.8487313234904076,
      "grad_norm": 0.9349040389060974,
      "learning_rate": 1.4343470061291845e-05,
      "loss": 0.3545,
      "step": 4800
    },
    {
      "epoch": 0.8664132260631244,
      "grad_norm": 2.0537269115448,
      "learning_rate": 1.4225601131541726e-05,
      "loss": 0.3425,
      "step": 4900
    },
    {
      "epoch": 0.8840951286358412,
      "grad_norm": 1.9099500179290771,
      "learning_rate": 1.4107732201791608e-05,
      "loss": 0.3333,
      "step": 5000
    },
    {
      "epoch": 0.901777031208558,
      "grad_norm": 1.1000571250915527,
      "learning_rate": 1.398986327204149e-05,
      "loss": 0.3448,
      "step": 5100
    },
    {
      "epoch": 0.9194589337812749,
      "grad_norm": 1.3409923315048218,
      "learning_rate": 1.3871994342291373e-05,
      "loss": 0.3276,
      "step": 5200
    },
    {
      "epoch": 0.9371408363539917,
      "grad_norm": 1.1824452877044678,
      "learning_rate": 1.3754125412541255e-05,
      "loss": 0.3316,
      "step": 5300
    },
    {
      "epoch": 0.9548227389267085,
      "grad_norm": 1.3334070444107056,
      "learning_rate": 1.3636256482791138e-05,
      "loss": 0.3316,
      "step": 5400
    },
    {
      "epoch": 0.9725046414994254,
      "grad_norm": 1.2182031869888306,
      "learning_rate": 1.3518387553041019e-05,
      "loss": 0.3398,
      "step": 5500
    },
    {
      "epoch": 0.9901865440721421,
      "grad_norm": 1.3730511665344238,
      "learning_rate": 1.3400518623290901e-05,
      "loss": 0.3289,
      "step": 5600
    },
    {
      "epoch": 1.0077800371319954,
      "grad_norm": 1.4308135509490967,
      "learning_rate": 1.3282649693540783e-05,
      "loss": 0.3099,
      "step": 5700
    },
    {
      "epoch": 1.0254619397047122,
      "grad_norm": 1.104025959968567,
      "learning_rate": 1.3164780763790666e-05,
      "loss": 0.281,
      "step": 5800
    },
    {
      "epoch": 1.043143842277429,
      "grad_norm": 0.9783188700675964,
      "learning_rate": 1.3046911834040548e-05,
      "loss": 0.2596,
      "step": 5900
    },
    {
      "epoch": 1.060825744850146,
      "grad_norm": 1.511965274810791,
      "learning_rate": 1.2929042904290429e-05,
      "loss": 0.2576,
      "step": 6000
    },
    {
      "epoch": 1.060825744850146,
      "eval_loss": 0.3287286162376404,
      "eval_runtime": 71.7015,
      "eval_samples_per_second": 157.751,
      "eval_steps_per_second": 19.721,
      "step": 6000
    },
    {
      "epoch": 1.0785076474228628,
      "grad_norm": 1.5178780555725098,
      "learning_rate": 1.2811173974540311e-05,
      "loss": 0.2732,
      "step": 6100
    },
    {
      "epoch": 1.0961895499955796,
      "grad_norm": 1.0893296003341675,
      "learning_rate": 1.2693305044790194e-05,
      "loss": 0.2538,
      "step": 6200
    },
    {
      "epoch": 1.1138714525682964,
      "grad_norm": 1.2002991437911987,
      "learning_rate": 1.2575436115040076e-05,
      "loss": 0.2568,
      "step": 6300
    },
    {
      "epoch": 1.1315533551410133,
      "grad_norm": 1.4256469011306763,
      "learning_rate": 1.2457567185289959e-05,
      "loss": 0.2666,
      "step": 6400
    },
    {
      "epoch": 1.14923525771373,
      "grad_norm": 1.2251092195510864,
      "learning_rate": 1.2339698255539841e-05,
      "loss": 0.266,
      "step": 6500
    },
    {
      "epoch": 1.1669171602864468,
      "grad_norm": 1.3018697500228882,
      "learning_rate": 1.2221829325789722e-05,
      "loss": 0.2704,
      "step": 6600
    },
    {
      "epoch": 1.1845990628591636,
      "grad_norm": 1.2485049962997437,
      "learning_rate": 1.2103960396039604e-05,
      "loss": 0.2687,
      "step": 6700
    },
    {
      "epoch": 1.2022809654318805,
      "grad_norm": 1.1079777479171753,
      "learning_rate": 1.1986091466289487e-05,
      "loss": 0.261,
      "step": 6800
    },
    {
      "epoch": 1.2199628680045973,
      "grad_norm": 1.230398416519165,
      "learning_rate": 1.1868222536539369e-05,
      "loss": 0.2659,
      "step": 6900
    },
    {
      "epoch": 1.2376447705773141,
      "grad_norm": 1.2704885005950928,
      "learning_rate": 1.1750353606789252e-05,
      "loss": 0.2587,
      "step": 7000
    },
    {
      "epoch": 1.255326673150031,
      "grad_norm": 0.9826038479804993,
      "learning_rate": 1.1632484677039132e-05,
      "loss": 0.2674,
      "step": 7100
    },
    {
      "epoch": 1.2730085757227478,
      "grad_norm": 1.1242599487304688,
      "learning_rate": 1.1514615747289015e-05,
      "loss": 0.2615,
      "step": 7200
    },
    {
      "epoch": 1.2906904782954647,
      "grad_norm": 1.1350960731506348,
      "learning_rate": 1.1396746817538897e-05,
      "loss": 0.2818,
      "step": 7300
    },
    {
      "epoch": 1.3083723808681813,
      "grad_norm": 1.0919535160064697,
      "learning_rate": 1.127887788778878e-05,
      "loss": 0.2684,
      "step": 7400
    },
    {
      "epoch": 1.3260542834408984,
      "grad_norm": 1.1540865898132324,
      "learning_rate": 1.1161008958038662e-05,
      "loss": 0.2624,
      "step": 7500
    },
    {
      "epoch": 1.3260542834408984,
      "eval_loss": 0.32725024223327637,
      "eval_runtime": 71.6677,
      "eval_samples_per_second": 157.826,
      "eval_steps_per_second": 19.73,
      "step": 7500
    },
    {
      "epoch": 1.343736186013615,
      "grad_norm": 0.8516194820404053,
      "learning_rate": 1.1043140028288544e-05,
      "loss": 0.2661,
      "step": 7600
    },
    {
      "epoch": 1.3614180885863318,
      "grad_norm": 1.7460083961486816,
      "learning_rate": 1.0925271098538425e-05,
      "loss": 0.2691,
      "step": 7700
    },
    {
      "epoch": 1.3790999911590487,
      "grad_norm": 1.210902452468872,
      "learning_rate": 1.0807402168788308e-05,
      "loss": 0.2717,
      "step": 7800
    },
    {
      "epoch": 1.3967818937317655,
      "grad_norm": 1.1606851816177368,
      "learning_rate": 1.068953323903819e-05,
      "loss": 0.2569,
      "step": 7900
    },
    {
      "epoch": 1.4144637963044824,
      "grad_norm": 1.1906546354293823,
      "learning_rate": 1.0571664309288072e-05,
      "loss": 0.2665,
      "step": 8000
    },
    {
      "epoch": 1.4321456988771992,
      "grad_norm": 1.2317841053009033,
      "learning_rate": 1.0453795379537955e-05,
      "loss": 0.26,
      "step": 8100
    },
    {
      "epoch": 1.449827601449916,
      "grad_norm": 0.9448175430297852,
      "learning_rate": 1.0335926449787836e-05,
      "loss": 0.2729,
      "step": 8200
    },
    {
      "epoch": 1.467509504022633,
      "grad_norm": 1.4986265897750854,
      "learning_rate": 1.0218057520037718e-05,
      "loss": 0.2645,
      "step": 8300
    },
    {
      "epoch": 1.4851914065953498,
      "grad_norm": 1.2577720880508423,
      "learning_rate": 1.01001885902876e-05,
      "loss": 0.2726,
      "step": 8400
    },
    {
      "epoch": 1.5028733091680664,
      "grad_norm": 1.2934824228286743,
      "learning_rate": 9.982319660537483e-06,
      "loss": 0.2696,
      "step": 8500
    },
    {
      "epoch": 1.5205552117407835,
      "grad_norm": 1.6359137296676636,
      "learning_rate": 9.864450730787365e-06,
      "loss": 0.2749,
      "step": 8600
    },
    {
      "epoch": 1.5382371143135,
      "grad_norm": 0.9849269390106201,
      "learning_rate": 9.746581801037248e-06,
      "loss": 0.2692,
      "step": 8700
    },
    {
      "epoch": 1.555919016886217,
      "grad_norm": 1.1420046091079712,
      "learning_rate": 9.628712871287129e-06,
      "loss": 0.2704,
      "step": 8800
    },
    {
      "epoch": 1.5736009194589338,
      "grad_norm": 1.4793471097946167,
      "learning_rate": 9.510843941537011e-06,
      "loss": 0.2706,
      "step": 8900
    },
    {
      "epoch": 1.5912828220316506,
      "grad_norm": 1.329829454421997,
      "learning_rate": 9.392975011786893e-06,
      "loss": 0.269,
      "step": 9000
    },
    {
      "epoch": 1.5912828220316506,
      "eval_loss": 0.32239893078804016,
      "eval_runtime": 72.5656,
      "eval_samples_per_second": 155.873,
      "eval_steps_per_second": 19.486,
      "step": 9000
    },
    {
      "epoch": 1.6089647246043675,
      "grad_norm": 1.2693625688552856,
      "learning_rate": 9.275106082036776e-06,
      "loss": 0.2665,
      "step": 9100
    },
    {
      "epoch": 1.6266466271770843,
      "grad_norm": 1.31780207157135,
      "learning_rate": 9.157237152286658e-06,
      "loss": 0.2616,
      "step": 9200
    },
    {
      "epoch": 1.6443285297498011,
      "grad_norm": 1.6055841445922852,
      "learning_rate": 9.039368222536539e-06,
      "loss": 0.2679,
      "step": 9300
    },
    {
      "epoch": 1.6620104323225178,
      "grad_norm": 1.0851988792419434,
      "learning_rate": 8.921499292786421e-06,
      "loss": 0.2736,
      "step": 9400
    },
    {
      "epoch": 1.6796923348952348,
      "grad_norm": 1.087312936782837,
      "learning_rate": 8.803630363036304e-06,
      "loss": 0.2613,
      "step": 9500
    },
    {
      "epoch": 1.6973742374679515,
      "grad_norm": 1.1813911199569702,
      "learning_rate": 8.685761433286186e-06,
      "loss": 0.2578,
      "step": 9600
    },
    {
      "epoch": 1.7150561400406685,
      "grad_norm": 1.099721908569336,
      "learning_rate": 8.567892503536069e-06,
      "loss": 0.2648,
      "step": 9700
    },
    {
      "epoch": 1.7327380426133852,
      "grad_norm": 1.0993129014968872,
      "learning_rate": 8.450023573785951e-06,
      "loss": 0.2708,
      "step": 9800
    },
    {
      "epoch": 1.750419945186102,
      "grad_norm": 0.7461479306221008,
      "learning_rate": 8.332154644035832e-06,
      "loss": 0.2564,
      "step": 9900
    },
    {
      "epoch": 1.7681018477588188,
      "grad_norm": 1.150920033454895,
      "learning_rate": 8.214285714285714e-06,
      "loss": 0.2589,
      "step": 10000
    },
    {
      "epoch": 1.7857837503315357,
      "grad_norm": 0.7060180306434631,
      "learning_rate": 8.096416784535597e-06,
      "loss": 0.2583,
      "step": 10100
    },
    {
      "epoch": 1.8034656529042525,
      "grad_norm": 1.2791662216186523,
      "learning_rate": 7.978547854785479e-06,
      "loss": 0.2802,
      "step": 10200
    },
    {
      "epoch": 1.8211475554769692,
      "grad_norm": 1.038979172706604,
      "learning_rate": 7.860678925035362e-06,
      "loss": 0.2496,
      "step": 10300
    },
    {
      "epoch": 1.8388294580496862,
      "grad_norm": 1.4813799858093262,
      "learning_rate": 7.742809995285242e-06,
      "loss": 0.26,
      "step": 10400
    },
    {
      "epoch": 1.8565113606224029,
      "grad_norm": 1.3384215831756592,
      "learning_rate": 7.624941065535126e-06,
      "loss": 0.2602,
      "step": 10500
    },
    {
      "epoch": 1.8565113606224029,
      "eval_loss": 0.32238444685935974,
      "eval_runtime": 72.1023,
      "eval_samples_per_second": 156.874,
      "eval_steps_per_second": 19.611,
      "step": 10500
    },
    {
      "epoch": 1.87419326319512,
      "grad_norm": 1.0947126150131226,
      "learning_rate": 7.507072135785007e-06,
      "loss": 0.2575,
      "step": 10600
    },
    {
      "epoch": 1.8918751657678365,
      "grad_norm": 1.3423137664794922,
      "learning_rate": 7.38920320603489e-06,
      "loss": 0.2718,
      "step": 10700
    },
    {
      "epoch": 1.9095570683405536,
      "grad_norm": 1.3973798751831055,
      "learning_rate": 7.271334276284772e-06,
      "loss": 0.2748,
      "step": 10800
    },
    {
      "epoch": 1.9272389709132702,
      "grad_norm": 1.532721757888794,
      "learning_rate": 7.153465346534654e-06,
      "loss": 0.2745,
      "step": 10900
    },
    {
      "epoch": 1.944920873485987,
      "grad_norm": 1.1686292886734009,
      "learning_rate": 7.035596416784536e-06,
      "loss": 0.2485,
      "step": 11000
    },
    {
      "epoch": 1.962602776058704,
      "grad_norm": 1.1097471714019775,
      "learning_rate": 6.917727487034418e-06,
      "loss": 0.2693,
      "step": 11100
    },
    {
      "epoch": 1.9802846786314208,
      "grad_norm": 1.0588442087173462,
      "learning_rate": 6.7998585572843e-06,
      "loss": 0.2562,
      "step": 11200
    },
    {
      "epoch": 1.9979665812041376,
      "grad_norm": 1.662617564201355,
      "learning_rate": 6.6819896275341825e-06,
      "loss": 0.2647,
      "step": 11300
    },
    {
      "epoch": 2.0155600742639908,
      "grad_norm": 1.2184596061706543,
      "learning_rate": 6.564120697784064e-06,
      "loss": 0.2243,
      "step": 11400
    },
    {
      "epoch": 2.033241976836708,
      "grad_norm": 0.9360759258270264,
      "learning_rate": 6.4462517680339465e-06,
      "loss": 0.2013,
      "step": 11500
    },
    {
      "epoch": 2.0509238794094244,
      "grad_norm": 1.3161035776138306,
      "learning_rate": 6.328382838283829e-06,
      "loss": 0.2109,
      "step": 11600
    },
    {
      "epoch": 2.068605781982141,
      "grad_norm": 1.1692670583724976,
      "learning_rate": 6.2105139085337105e-06,
      "loss": 0.2068,
      "step": 11700
    },
    {
      "epoch": 2.086287684554858,
      "grad_norm": 1.212350606918335,
      "learning_rate": 6.092644978783593e-06,
      "loss": 0.2164,
      "step": 11800
    },
    {
      "epoch": 2.1039695871275748,
      "grad_norm": 1.1400104761123657,
      "learning_rate": 5.974776049033475e-06,
      "loss": 0.2012,
      "step": 11900
    },
    {
      "epoch": 2.121651489700292,
      "grad_norm": 1.0902303457260132,
      "learning_rate": 5.856907119283357e-06,
      "loss": 0.2154,
      "step": 12000
    },
    {
      "epoch": 2.121651489700292,
      "eval_loss": 0.33144888281822205,
      "eval_runtime": 72.5971,
      "eval_samples_per_second": 155.805,
      "eval_steps_per_second": 19.477,
      "step": 12000
    },
    {
      "epoch": 2.1393333922730084,
      "grad_norm": 1.0773594379425049,
      "learning_rate": 5.739038189533239e-06,
      "loss": 0.2218,
      "step": 12100
    },
    {
      "epoch": 2.1570152948457255,
      "grad_norm": 1.5531576871871948,
      "learning_rate": 5.621169259783121e-06,
      "loss": 0.2117,
      "step": 12200
    },
    {
      "epoch": 2.174697197418442,
      "grad_norm": 1.1061456203460693,
      "learning_rate": 5.503300330033003e-06,
      "loss": 0.2068,
      "step": 12300
    },
    {
      "epoch": 2.192379099991159,
      "grad_norm": 1.2045947313308716,
      "learning_rate": 5.385431400282886e-06,
      "loss": 0.2025,
      "step": 12400
    },
    {
      "epoch": 2.210061002563876,
      "grad_norm": 1.2053782939910889,
      "learning_rate": 5.267562470532767e-06,
      "loss": 0.2207,
      "step": 12500
    },
    {
      "epoch": 2.227742905136593,
      "grad_norm": 1.7043657302856445,
      "learning_rate": 5.14969354078265e-06,
      "loss": 0.2221,
      "step": 12600
    },
    {
      "epoch": 2.2454248077093095,
      "grad_norm": 1.4885404109954834,
      "learning_rate": 5.031824611032532e-06,
      "loss": 0.2022,
      "step": 12700
    },
    {
      "epoch": 2.2631067102820266,
      "grad_norm": 1.081127643585205,
      "learning_rate": 4.913955681282415e-06,
      "loss": 0.2055,
      "step": 12800
    },
    {
      "epoch": 2.280788612854743,
      "grad_norm": 1.2094770669937134,
      "learning_rate": 4.796086751532297e-06,
      "loss": 0.2116,
      "step": 12900
    },
    {
      "epoch": 2.29847051542746,
      "grad_norm": 1.0101826190948486,
      "learning_rate": 4.678217821782179e-06,
      "loss": 0.2075,
      "step": 13000
    },
    {
      "epoch": 2.316152418000177,
      "grad_norm": 1.2088871002197266,
      "learning_rate": 4.560348892032061e-06,
      "loss": 0.2015,
      "step": 13100
    },
    {
      "epoch": 2.3338343205728935,
      "grad_norm": 1.2958707809448242,
      "learning_rate": 4.442479962281943e-06,
      "loss": 0.2079,
      "step": 13200
    },
    {
      "epoch": 2.3515162231456106,
      "grad_norm": 1.5805261135101318,
      "learning_rate": 4.324611032531825e-06,
      "loss": 0.2141,
      "step": 13300
    },
    {
      "epoch": 2.369198125718327,
      "grad_norm": 1.1367253065109253,
      "learning_rate": 4.206742102781708e-06,
      "loss": 0.2109,
      "step": 13400
    },
    {
      "epoch": 2.3868800282910443,
      "grad_norm": 1.2176860570907593,
      "learning_rate": 4.088873173031589e-06,
      "loss": 0.2125,
      "step": 13500
    },
    {
      "epoch": 2.3868800282910443,
      "eval_loss": 0.3307560384273529,
      "eval_runtime": 72.4691,
      "eval_samples_per_second": 156.08,
      "eval_steps_per_second": 19.512,
      "step": 13500
    },
    {
      "epoch": 2.404561930863761,
      "grad_norm": 1.6348820924758911,
      "learning_rate": 3.971004243281472e-06,
      "loss": 0.2131,
      "step": 13600
    },
    {
      "epoch": 2.422243833436478,
      "grad_norm": 1.2629860639572144,
      "learning_rate": 3.853135313531354e-06,
      "loss": 0.1924,
      "step": 13700
    },
    {
      "epoch": 2.4399257360091946,
      "grad_norm": 0.6454944014549255,
      "learning_rate": 3.735266383781235e-06,
      "loss": 0.22,
      "step": 13800
    },
    {
      "epoch": 2.4576076385819112,
      "grad_norm": 1.1481571197509766,
      "learning_rate": 3.6173974540311176e-06,
      "loss": 0.1949,
      "step": 13900
    },
    {
      "epoch": 2.4752895411546283,
      "grad_norm": 1.129586935043335,
      "learning_rate": 3.4995285242809996e-06,
      "loss": 0.2154,
      "step": 14000
    },
    {
      "epoch": 2.492971443727345,
      "grad_norm": 1.4451390504837036,
      "learning_rate": 3.3816595945308816e-06,
      "loss": 0.1908,
      "step": 14100
    },
    {
      "epoch": 2.510653346300062,
      "grad_norm": 1.2087061405181885,
      "learning_rate": 3.2637906647807636e-06,
      "loss": 0.202,
      "step": 14200
    },
    {
      "epoch": 2.5283352488727786,
      "grad_norm": 1.2263052463531494,
      "learning_rate": 3.145921735030646e-06,
      "loss": 0.2092,
      "step": 14300
    },
    {
      "epoch": 2.5460171514454957,
      "grad_norm": 1.074299693107605,
      "learning_rate": 3.028052805280528e-06,
      "loss": 0.1998,
      "step": 14400
    },
    {
      "epoch": 2.5636990540182123,
      "grad_norm": 1.4316306114196777,
      "learning_rate": 2.91018387553041e-06,
      "loss": 0.2166,
      "step": 14500
    },
    {
      "epoch": 2.5813809565909294,
      "grad_norm": 1.294882893562317,
      "learning_rate": 2.792314945780292e-06,
      "loss": 0.2107,
      "step": 14600
    },
    {
      "epoch": 2.599062859163646,
      "grad_norm": 1.7270466089248657,
      "learning_rate": 2.6744460160301745e-06,
      "loss": 0.2118,
      "step": 14700
    },
    {
      "epoch": 2.6167447617363626,
      "grad_norm": 1.5897183418273926,
      "learning_rate": 2.5565770862800565e-06,
      "loss": 0.2063,
      "step": 14800
    },
    {
      "epoch": 2.6344266643090797,
      "grad_norm": 1.3389118909835815,
      "learning_rate": 2.438708156529939e-06,
      "loss": 0.2137,
      "step": 14900
    },
    {
      "epoch": 2.6521085668817967,
      "grad_norm": 1.0480968952178955,
      "learning_rate": 2.320839226779821e-06,
      "loss": 0.2062,
      "step": 15000
    },
    {
      "epoch": 2.6521085668817967,
      "eval_loss": 0.33029070496559143,
      "eval_runtime": 72.4828,
      "eval_samples_per_second": 156.051,
      "eval_steps_per_second": 19.508,
      "step": 15000
    },
    {
      "epoch": 2.6697904694545134,
      "grad_norm": 1.8571758270263672,
      "learning_rate": 2.202970297029703e-06,
      "loss": 0.2051,
      "step": 15100
    },
    {
      "epoch": 2.68747237202723,
      "grad_norm": 1.2202835083007812,
      "learning_rate": 2.0851013672795854e-06,
      "loss": 0.2179,
      "step": 15200
    },
    {
      "epoch": 2.705154274599947,
      "grad_norm": 1.2873518466949463,
      "learning_rate": 1.9672324375294674e-06,
      "loss": 0.2152,
      "step": 15300
    },
    {
      "epoch": 2.7228361771726637,
      "grad_norm": 0.9462004899978638,
      "learning_rate": 1.8493635077793496e-06,
      "loss": 0.2121,
      "step": 15400
    },
    {
      "epoch": 2.7405180797453808,
      "grad_norm": 0.9667515754699707,
      "learning_rate": 1.7314945780292316e-06,
      "loss": 0.2085,
      "step": 15500
    },
    {
      "epoch": 2.7581999823180974,
      "grad_norm": 1.7122998237609863,
      "learning_rate": 1.6136256482791138e-06,
      "loss": 0.2087,
      "step": 15600
    },
    {
      "epoch": 2.775881884890814,
      "grad_norm": 1.2905995845794678,
      "learning_rate": 1.4957567185289958e-06,
      "loss": 0.2154,
      "step": 15700
    },
    {
      "epoch": 2.793563787463531,
      "grad_norm": 0.8195710778236389,
      "learning_rate": 1.377887788778878e-06,
      "loss": 0.2116,
      "step": 15800
    },
    {
      "epoch": 2.811245690036248,
      "grad_norm": 1.4692224264144897,
      "learning_rate": 1.26001885902876e-06,
      "loss": 0.2007,
      "step": 15900
    },
    {
      "epoch": 2.8289275926089648,
      "grad_norm": 0.915276825428009,
      "learning_rate": 1.1421499292786423e-06,
      "loss": 0.2003,
      "step": 16000
    },
    {
      "epoch": 2.8466094951816814,
      "grad_norm": 1.115108609199524,
      "learning_rate": 1.0242809995285243e-06,
      "loss": 0.2088,
      "step": 16100
    },
    {
      "epoch": 2.8642913977543984,
      "grad_norm": 1.4374244213104248,
      "learning_rate": 9.064120697784065e-07,
      "loss": 0.2014,
      "step": 16200
    },
    {
      "epoch": 2.881973300327115,
      "grad_norm": 0.8658066391944885,
      "learning_rate": 7.885431400282886e-07,
      "loss": 0.2121,
      "step": 16300
    },
    {
      "epoch": 2.899655202899832,
      "grad_norm": 1.514195203781128,
      "learning_rate": 6.706742102781707e-07,
      "loss": 0.2132,
      "step": 16400
    },
    {
      "epoch": 2.9173371054725488,
      "grad_norm": 0.9984769225120544,
      "learning_rate": 5.528052805280528e-07,
      "loss": 0.2081,
      "step": 16500
    },
    {
      "epoch": 2.9173371054725488,
      "eval_loss": 0.3283507227897644,
      "eval_runtime": 72.6082,
      "eval_samples_per_second": 155.781,
      "eval_steps_per_second": 19.474,
      "step": 16500
    },
    {
      "epoch": 2.935019008045266,
      "grad_norm": 1.2512801885604858,
      "learning_rate": 4.34936350777935e-07,
      "loss": 0.2131,
      "step": 16600
    },
    {
      "epoch": 2.9527009106179825,
      "grad_norm": 0.958526074886322,
      "learning_rate": 3.170674210278171e-07,
      "loss": 0.2076,
      "step": 16700
    },
    {
      "epoch": 2.9703828131906995,
      "grad_norm": 1.4325432777404785,
      "learning_rate": 1.991984912776992e-07,
      "loss": 0.2088,
      "step": 16800
    },
    {
      "epoch": 2.988064715763416,
      "grad_norm": 1.690530776977539,
      "learning_rate": 8.132956152758134e-08,
      "loss": 0.2076,
      "step": 16900
    }
  ],
  "logging_steps": 100,
  "max_steps": 16968,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.353721441537229e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
