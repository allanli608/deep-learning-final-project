{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8484,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008840951286358412,
      "grad_norm": 4.204138278961182,
      "learning_rate": 2.9913366336633666e-05,
      "loss": 1.6935,
      "step": 50
    },
    {
      "epoch": 0.017681902572716825,
      "grad_norm": 2.0408737659454346,
      "learning_rate": 2.9824964639321076e-05,
      "loss": 0.5242,
      "step": 100
    },
    {
      "epoch": 0.026522853859075237,
      "grad_norm": 2.394523859024048,
      "learning_rate": 2.9736562942008487e-05,
      "loss": 0.455,
      "step": 150
    },
    {
      "epoch": 0.03536380514543365,
      "grad_norm": 1.3891263008117676,
      "learning_rate": 2.9648161244695897e-05,
      "loss": 0.4451,
      "step": 200
    },
    {
      "epoch": 0.04420475643179206,
      "grad_norm": 1.7201695442199707,
      "learning_rate": 2.955975954738331e-05,
      "loss": 0.4433,
      "step": 250
    },
    {
      "epoch": 0.053045707718150474,
      "grad_norm": 1.6474950313568115,
      "learning_rate": 2.9471357850070722e-05,
      "loss": 0.4152,
      "step": 300
    },
    {
      "epoch": 0.06188665900450888,
      "grad_norm": 1.8319329023361206,
      "learning_rate": 2.9382956152758136e-05,
      "loss": 0.4175,
      "step": 350
    },
    {
      "epoch": 0.0707276102908673,
      "grad_norm": 2.126920223236084,
      "learning_rate": 2.9294554455445543e-05,
      "loss": 0.4331,
      "step": 400
    },
    {
      "epoch": 0.07956856157722571,
      "grad_norm": 1.373007893562317,
      "learning_rate": 2.9206152758132957e-05,
      "loss": 0.4095,
      "step": 450
    },
    {
      "epoch": 0.08840951286358412,
      "grad_norm": 1.9014312028884888,
      "learning_rate": 2.9117751060820368e-05,
      "loss": 0.3783,
      "step": 500
    },
    {
      "epoch": 0.08840951286358412,
      "eval_loss": 0.3976268172264099,
      "eval_runtime": 71.6499,
      "eval_samples_per_second": 157.865,
      "eval_steps_per_second": 19.735,
      "step": 500
    },
    {
      "epoch": 0.09725046414994254,
      "grad_norm": 1.0406391620635986,
      "learning_rate": 2.902934936350778e-05,
      "loss": 0.412,
      "step": 550
    },
    {
      "epoch": 0.10609141543630095,
      "grad_norm": 1.3150438070297241,
      "learning_rate": 2.8940947666195192e-05,
      "loss": 0.3623,
      "step": 600
    },
    {
      "epoch": 0.11493236672265936,
      "grad_norm": 1.6831989288330078,
      "learning_rate": 2.8852545968882606e-05,
      "loss": 0.386,
      "step": 650
    },
    {
      "epoch": 0.12377331800901777,
      "grad_norm": 1.8781824111938477,
      "learning_rate": 2.8764144271570013e-05,
      "loss": 0.3891,
      "step": 700
    },
    {
      "epoch": 0.13261426929537617,
      "grad_norm": 1.1815851926803589,
      "learning_rate": 2.8675742574257427e-05,
      "loss": 0.3952,
      "step": 750
    },
    {
      "epoch": 0.1414552205817346,
      "grad_norm": 1.4367163181304932,
      "learning_rate": 2.8587340876944838e-05,
      "loss": 0.3777,
      "step": 800
    },
    {
      "epoch": 0.15029617186809302,
      "grad_norm": 1.1320921182632446,
      "learning_rate": 2.849893917963225e-05,
      "loss": 0.3833,
      "step": 850
    },
    {
      "epoch": 0.15913712315445142,
      "grad_norm": 1.5496132373809814,
      "learning_rate": 2.8410537482319662e-05,
      "loss": 0.3849,
      "step": 900
    },
    {
      "epoch": 0.16797807444080984,
      "grad_norm": 1.0103932619094849,
      "learning_rate": 2.8322135785007073e-05,
      "loss": 0.4065,
      "step": 950
    },
    {
      "epoch": 0.17681902572716823,
      "grad_norm": 3.1479640007019043,
      "learning_rate": 2.8233734087694483e-05,
      "loss": 0.3657,
      "step": 1000
    },
    {
      "epoch": 0.17681902572716823,
      "eval_loss": 0.3736099302768707,
      "eval_runtime": 71.2697,
      "eval_samples_per_second": 158.707,
      "eval_steps_per_second": 19.84,
      "step": 1000
    },
    {
      "epoch": 0.18565997701352666,
      "grad_norm": 1.0851261615753174,
      "learning_rate": 2.8145332390381897e-05,
      "loss": 0.363,
      "step": 1050
    },
    {
      "epoch": 0.19450092829988508,
      "grad_norm": 1.0212103128433228,
      "learning_rate": 2.8056930693069308e-05,
      "loss": 0.3726,
      "step": 1100
    },
    {
      "epoch": 0.20334187958624347,
      "grad_norm": 1.4897314310073853,
      "learning_rate": 2.796852899575672e-05,
      "loss": 0.3497,
      "step": 1150
    },
    {
      "epoch": 0.2121828308726019,
      "grad_norm": 1.3097013235092163,
      "learning_rate": 2.788012729844413e-05,
      "loss": 0.3914,
      "step": 1200
    },
    {
      "epoch": 0.2210237821589603,
      "grad_norm": 1.058799147605896,
      "learning_rate": 2.7791725601131543e-05,
      "loss": 0.377,
      "step": 1250
    },
    {
      "epoch": 0.22986473344531871,
      "grad_norm": 1.156568169593811,
      "learning_rate": 2.7703323903818953e-05,
      "loss": 0.3837,
      "step": 1300
    },
    {
      "epoch": 0.23870568473167714,
      "grad_norm": 1.3482229709625244,
      "learning_rate": 2.7614922206506367e-05,
      "loss": 0.3663,
      "step": 1350
    },
    {
      "epoch": 0.24754663601803553,
      "grad_norm": 1.22072172164917,
      "learning_rate": 2.7526520509193778e-05,
      "loss": 0.3794,
      "step": 1400
    },
    {
      "epoch": 0.2563875873043939,
      "grad_norm": 1.2460086345672607,
      "learning_rate": 2.743811881188119e-05,
      "loss": 0.374,
      "step": 1450
    },
    {
      "epoch": 0.26522853859075235,
      "grad_norm": 1.6191322803497314,
      "learning_rate": 2.73497171145686e-05,
      "loss": 0.3785,
      "step": 1500
    },
    {
      "epoch": 0.26522853859075235,
      "eval_loss": 0.359637588262558,
      "eval_runtime": 71.5486,
      "eval_samples_per_second": 158.088,
      "eval_steps_per_second": 19.763,
      "step": 1500
    },
    {
      "epoch": 0.2740694898771108,
      "grad_norm": 1.1558468341827393,
      "learning_rate": 2.7261315417256013e-05,
      "loss": 0.3538,
      "step": 1550
    },
    {
      "epoch": 0.2829104411634692,
      "grad_norm": 5.178854942321777,
      "learning_rate": 2.7172913719943423e-05,
      "loss": 0.3738,
      "step": 1600
    },
    {
      "epoch": 0.2917513924498276,
      "grad_norm": 1.0762577056884766,
      "learning_rate": 2.7084512022630837e-05,
      "loss": 0.3877,
      "step": 1650
    },
    {
      "epoch": 0.30059234373618604,
      "grad_norm": 1.3657863140106201,
      "learning_rate": 2.6996110325318245e-05,
      "loss": 0.356,
      "step": 1700
    },
    {
      "epoch": 0.3094332950225444,
      "grad_norm": 1.2813407182693481,
      "learning_rate": 2.690770862800566e-05,
      "loss": 0.372,
      "step": 1750
    },
    {
      "epoch": 0.31827424630890283,
      "grad_norm": 1.5324093103408813,
      "learning_rate": 2.681930693069307e-05,
      "loss": 0.3763,
      "step": 1800
    },
    {
      "epoch": 0.32711519759526125,
      "grad_norm": 1.1875696182250977,
      "learning_rate": 2.6730905233380483e-05,
      "loss": 0.3763,
      "step": 1850
    },
    {
      "epoch": 0.3359561488816197,
      "grad_norm": 1.1729893684387207,
      "learning_rate": 2.6642503536067893e-05,
      "loss": 0.3663,
      "step": 1900
    },
    {
      "epoch": 0.3447971001679781,
      "grad_norm": 1.1006931066513062,
      "learning_rate": 2.6554101838755307e-05,
      "loss": 0.36,
      "step": 1950
    },
    {
      "epoch": 0.35363805145433647,
      "grad_norm": 1.2845840454101562,
      "learning_rate": 2.6465700141442715e-05,
      "loss": 0.3559,
      "step": 2000
    },
    {
      "epoch": 0.35363805145433647,
      "eval_loss": 0.3510778546333313,
      "eval_runtime": 71.3246,
      "eval_samples_per_second": 158.585,
      "eval_steps_per_second": 19.825,
      "step": 2000
    },
    {
      "epoch": 0.3624790027406949,
      "grad_norm": 1.0851142406463623,
      "learning_rate": 2.637729844413013e-05,
      "loss": 0.3382,
      "step": 2050
    },
    {
      "epoch": 0.3713199540270533,
      "grad_norm": 1.350598692893982,
      "learning_rate": 2.628889674681754e-05,
      "loss": 0.3773,
      "step": 2100
    },
    {
      "epoch": 0.38016090531341173,
      "grad_norm": 1.0473254919052124,
      "learning_rate": 2.6200495049504953e-05,
      "loss": 0.3557,
      "step": 2150
    },
    {
      "epoch": 0.38900185659977016,
      "grad_norm": 0.9389293193817139,
      "learning_rate": 2.6112093352192364e-05,
      "loss": 0.3503,
      "step": 2200
    },
    {
      "epoch": 0.3978428078861285,
      "grad_norm": 1.2513123750686646,
      "learning_rate": 2.6023691654879774e-05,
      "loss": 0.3729,
      "step": 2250
    },
    {
      "epoch": 0.40668375917248695,
      "grad_norm": 1.4401524066925049,
      "learning_rate": 2.5935289957567185e-05,
      "loss": 0.3626,
      "step": 2300
    },
    {
      "epoch": 0.41552471045884537,
      "grad_norm": 1.2267946004867554,
      "learning_rate": 2.58468882602546e-05,
      "loss": 0.3786,
      "step": 2350
    },
    {
      "epoch": 0.4243656617452038,
      "grad_norm": 1.3033533096313477,
      "learning_rate": 2.575848656294201e-05,
      "loss": 0.3451,
      "step": 2400
    },
    {
      "epoch": 0.4332066130315622,
      "grad_norm": 0.8887606859207153,
      "learning_rate": 2.5670084865629423e-05,
      "loss": 0.3741,
      "step": 2450
    },
    {
      "epoch": 0.4420475643179206,
      "grad_norm": 1.0394378900527954,
      "learning_rate": 2.558168316831683e-05,
      "loss": 0.351,
      "step": 2500
    },
    {
      "epoch": 0.4420475643179206,
      "eval_loss": 0.34797993302345276,
      "eval_runtime": 71.5068,
      "eval_samples_per_second": 158.181,
      "eval_steps_per_second": 19.774,
      "step": 2500
    },
    {
      "epoch": 0.450888515604279,
      "grad_norm": 2.298558235168457,
      "learning_rate": 2.5493281471004244e-05,
      "loss": 0.3496,
      "step": 2550
    },
    {
      "epoch": 0.45972946689063743,
      "grad_norm": 1.9395263195037842,
      "learning_rate": 2.5404879773691655e-05,
      "loss": 0.3523,
      "step": 2600
    },
    {
      "epoch": 0.46857041817699585,
      "grad_norm": 1.0208306312561035,
      "learning_rate": 2.531647807637907e-05,
      "loss": 0.3535,
      "step": 2650
    },
    {
      "epoch": 0.4774113694633543,
      "grad_norm": 0.9698967933654785,
      "learning_rate": 2.522807637906648e-05,
      "loss": 0.3636,
      "step": 2700
    },
    {
      "epoch": 0.4862523207497127,
      "grad_norm": 1.1995153427124023,
      "learning_rate": 2.513967468175389e-05,
      "loss": 0.3709,
      "step": 2750
    },
    {
      "epoch": 0.49509327203607106,
      "grad_norm": 0.9749190807342529,
      "learning_rate": 2.50512729844413e-05,
      "loss": 0.3573,
      "step": 2800
    },
    {
      "epoch": 0.5039342233224295,
      "grad_norm": 1.4064842462539673,
      "learning_rate": 2.4962871287128714e-05,
      "loss": 0.333,
      "step": 2850
    },
    {
      "epoch": 0.5127751746087879,
      "grad_norm": 1.1951731443405151,
      "learning_rate": 2.4874469589816125e-05,
      "loss": 0.3768,
      "step": 2900
    },
    {
      "epoch": 0.5216161258951463,
      "grad_norm": 1.4139647483825684,
      "learning_rate": 2.478606789250354e-05,
      "loss": 0.378,
      "step": 2950
    },
    {
      "epoch": 0.5304570771815047,
      "grad_norm": 1.064597249031067,
      "learning_rate": 2.469766619519095e-05,
      "loss": 0.3328,
      "step": 3000
    },
    {
      "epoch": 0.5304570771815047,
      "eval_loss": 0.344046026468277,
      "eval_runtime": 71.3617,
      "eval_samples_per_second": 158.502,
      "eval_steps_per_second": 19.815,
      "step": 3000
    },
    {
      "epoch": 0.5392980284678631,
      "grad_norm": 1.2584218978881836,
      "learning_rate": 2.460926449787836e-05,
      "loss": 0.3451,
      "step": 3050
    },
    {
      "epoch": 0.5481389797542215,
      "grad_norm": 1.1610859632492065,
      "learning_rate": 2.452086280056577e-05,
      "loss": 0.3385,
      "step": 3100
    },
    {
      "epoch": 0.55697993104058,
      "grad_norm": 1.289120078086853,
      "learning_rate": 2.4432461103253184e-05,
      "loss": 0.3668,
      "step": 3150
    },
    {
      "epoch": 0.5658208823269384,
      "grad_norm": 0.9592005610466003,
      "learning_rate": 2.4344059405940595e-05,
      "loss": 0.3492,
      "step": 3200
    },
    {
      "epoch": 0.5746618336132968,
      "grad_norm": 1.117816686630249,
      "learning_rate": 2.425565770862801e-05,
      "loss": 0.38,
      "step": 3250
    },
    {
      "epoch": 0.5835027848996552,
      "grad_norm": 1.2708687782287598,
      "learning_rate": 2.4167256011315416e-05,
      "loss": 0.3406,
      "step": 3300
    },
    {
      "epoch": 0.5923437361860137,
      "grad_norm": 1.6477341651916504,
      "learning_rate": 2.407885431400283e-05,
      "loss": 0.3337,
      "step": 3350
    },
    {
      "epoch": 0.6011846874723721,
      "grad_norm": 0.7684739828109741,
      "learning_rate": 2.399045261669024e-05,
      "loss": 0.3488,
      "step": 3400
    },
    {
      "epoch": 0.6100256387587304,
      "grad_norm": 1.1890424489974976,
      "learning_rate": 2.3902050919377654e-05,
      "loss": 0.3586,
      "step": 3450
    },
    {
      "epoch": 0.6188665900450888,
      "grad_norm": 1.3750096559524536,
      "learning_rate": 2.3813649222065065e-05,
      "loss": 0.3385,
      "step": 3500
    },
    {
      "epoch": 0.6188665900450888,
      "eval_loss": 0.34948015213012695,
      "eval_runtime": 71.5752,
      "eval_samples_per_second": 158.03,
      "eval_steps_per_second": 19.755,
      "step": 3500
    },
    {
      "epoch": 0.6277075413314472,
      "grad_norm": 0.9905378222465515,
      "learning_rate": 2.3725247524752476e-05,
      "loss": 0.3638,
      "step": 3550
    },
    {
      "epoch": 0.6365484926178057,
      "grad_norm": 1.416257381439209,
      "learning_rate": 2.3636845827439886e-05,
      "loss": 0.3288,
      "step": 3600
    },
    {
      "epoch": 0.6453894439041641,
      "grad_norm": 1.3184758424758911,
      "learning_rate": 2.35484441301273e-05,
      "loss": 0.3255,
      "step": 3650
    },
    {
      "epoch": 0.6542303951905225,
      "grad_norm": 0.9821849465370178,
      "learning_rate": 2.346004243281471e-05,
      "loss": 0.3564,
      "step": 3700
    },
    {
      "epoch": 0.6630713464768809,
      "grad_norm": 1.2751386165618896,
      "learning_rate": 2.3371640735502125e-05,
      "loss": 0.3503,
      "step": 3750
    },
    {
      "epoch": 0.6719122977632394,
      "grad_norm": 0.9552265405654907,
      "learning_rate": 2.3283239038189532e-05,
      "loss": 0.3381,
      "step": 3800
    },
    {
      "epoch": 0.6807532490495978,
      "grad_norm": 1.2663463354110718,
      "learning_rate": 2.3194837340876946e-05,
      "loss": 0.3399,
      "step": 3850
    },
    {
      "epoch": 0.6895942003359562,
      "grad_norm": 1.026849627494812,
      "learning_rate": 2.3106435643564356e-05,
      "loss": 0.3304,
      "step": 3900
    },
    {
      "epoch": 0.6984351516223145,
      "grad_norm": 1.0142468214035034,
      "learning_rate": 2.301803394625177e-05,
      "loss": 0.3493,
      "step": 3950
    },
    {
      "epoch": 0.7072761029086729,
      "grad_norm": 1.0405291318893433,
      "learning_rate": 2.292963224893918e-05,
      "loss": 0.3382,
      "step": 4000
    },
    {
      "epoch": 0.7072761029086729,
      "eval_loss": 0.3389837443828583,
      "eval_runtime": 71.6661,
      "eval_samples_per_second": 157.829,
      "eval_steps_per_second": 19.73,
      "step": 4000
    },
    {
      "epoch": 1.4321456988771992,
      "grad_norm": 0.8877469301223755,
      "learning_rate": 1.5682461103253182e-05,
      "loss": 0.2517,
      "step": 4050
    },
    {
      "epoch": 1.449827601449916,
      "grad_norm": 0.5442034602165222,
      "learning_rate": 1.5505657708628006e-05,
      "loss": 0.2339,
      "step": 4100
    },
    {
      "epoch": 1.467509504022633,
      "grad_norm": 0.6961764097213745,
      "learning_rate": 1.5328854314002827e-05,
      "loss": 0.2373,
      "step": 4150
    },
    {
      "epoch": 1.4851914065953498,
      "grad_norm": 0.8488296866416931,
      "learning_rate": 1.5152050919377652e-05,
      "loss": 0.2482,
      "step": 4200
    },
    {
      "epoch": 1.5028733091680664,
      "grad_norm": 0.8965479135513306,
      "learning_rate": 1.4975247524752476e-05,
      "loss": 0.223,
      "step": 4250
    },
    {
      "epoch": 1.5205552117407835,
      "grad_norm": 0.6256738305091858,
      "learning_rate": 1.4798444130127299e-05,
      "loss": 0.2514,
      "step": 4300
    },
    {
      "epoch": 1.5382371143135,
      "grad_norm": 0.9373422861099243,
      "learning_rate": 1.4621640735502122e-05,
      "loss": 0.214,
      "step": 4350
    },
    {
      "epoch": 1.555919016886217,
      "grad_norm": 0.5971823334693909,
      "learning_rate": 1.4444837340876946e-05,
      "loss": 0.229,
      "step": 4400
    },
    {
      "epoch": 1.5736009194589338,
      "grad_norm": 0.8554553389549255,
      "learning_rate": 1.426803394625177e-05,
      "loss": 0.2396,
      "step": 4450
    },
    {
      "epoch": 1.5912828220316506,
      "grad_norm": 1.0608155727386475,
      "learning_rate": 1.4091230551626592e-05,
      "loss": 0.2142,
      "step": 4500
    },
    {
      "epoch": 1.5912828220316506,
      "eval_loss": 0.3444671928882599,
      "eval_runtime": 71.6664,
      "eval_samples_per_second": 157.828,
      "eval_steps_per_second": 19.73,
      "step": 4500
    },
    {
      "epoch": 1.6089647246043675,
      "grad_norm": 0.8653492331504822,
      "learning_rate": 1.3914427157001415e-05,
      "loss": 0.2332,
      "step": 4550
    },
    {
      "epoch": 1.6266466271770843,
      "grad_norm": 0.7354731559753418,
      "learning_rate": 1.373762376237624e-05,
      "loss": 0.2219,
      "step": 4600
    },
    {
      "epoch": 1.6443285297498011,
      "grad_norm": 0.9463016390800476,
      "learning_rate": 1.3560820367751062e-05,
      "loss": 0.206,
      "step": 4650
    },
    {
      "epoch": 1.6620104323225178,
      "grad_norm": 0.9813158512115479,
      "learning_rate": 1.3384016973125885e-05,
      "loss": 0.2254,
      "step": 4700
    },
    {
      "epoch": 1.6796923348952348,
      "grad_norm": 0.711490273475647,
      "learning_rate": 1.3207213578500708e-05,
      "loss": 0.21,
      "step": 4750
    },
    {
      "epoch": 1.6973742374679515,
      "grad_norm": 0.7233763337135315,
      "learning_rate": 1.303041018387553e-05,
      "loss": 0.2121,
      "step": 4800
    },
    {
      "epoch": 1.7150561400406685,
      "grad_norm": 0.96966153383255,
      "learning_rate": 1.2853606789250355e-05,
      "loss": 0.2796,
      "step": 4850
    },
    {
      "epoch": 1.7327380426133852,
      "grad_norm": 0.7966775298118591,
      "learning_rate": 1.2676803394625178e-05,
      "loss": 0.3243,
      "step": 4900
    },
    {
      "epoch": 1.750419945186102,
      "grad_norm": 0.7225178480148315,
      "learning_rate": 1.25e-05,
      "loss": 0.3319,
      "step": 4950
    },
    {
      "epoch": 1.7681018477588188,
      "grad_norm": 0.9660347700119019,
      "learning_rate": 1.2323196605374823e-05,
      "loss": 0.3494,
      "step": 5000
    },
    {
      "epoch": 1.7681018477588188,
      "eval_loss": 0.3250843286514282,
      "eval_runtime": 72.088,
      "eval_samples_per_second": 156.906,
      "eval_steps_per_second": 19.615,
      "step": 5000
    },
    {
      "epoch": 1.7857837503315357,
      "grad_norm": 0.862917959690094,
      "learning_rate": 1.2146393210749648e-05,
      "loss": 0.3283,
      "step": 5050
    },
    {
      "epoch": 1.8034656529042525,
      "grad_norm": 0.746930718421936,
      "learning_rate": 1.196958981612447e-05,
      "loss": 0.3239,
      "step": 5100
    },
    {
      "epoch": 1.8211475554769692,
      "grad_norm": 0.827663779258728,
      "learning_rate": 1.1792786421499293e-05,
      "loss": 0.3235,
      "step": 5150
    },
    {
      "epoch": 1.8388294580496862,
      "grad_norm": 0.9064557552337646,
      "learning_rate": 1.1615983026874116e-05,
      "loss": 0.3518,
      "step": 5200
    },
    {
      "epoch": 1.8565113606224029,
      "grad_norm": 0.8770850896835327,
      "learning_rate": 1.143917963224894e-05,
      "loss": 0.3325,
      "step": 5250
    },
    {
      "epoch": 1.87419326319512,
      "grad_norm": 0.6618571281433105,
      "learning_rate": 1.1262376237623764e-05,
      "loss": 0.3403,
      "step": 5300
    },
    {
      "epoch": 1.8918751657678365,
      "grad_norm": 0.8493630886077881,
      "learning_rate": 1.1085572842998586e-05,
      "loss": 0.3279,
      "step": 5350
    },
    {
      "epoch": 1.9095570683405536,
      "grad_norm": 0.7920833826065063,
      "learning_rate": 1.090876944837341e-05,
      "loss": 0.3323,
      "step": 5400
    },
    {
      "epoch": 1.9272389709132702,
      "grad_norm": 0.7695683240890503,
      "learning_rate": 1.0731966053748232e-05,
      "loss": 0.3213,
      "step": 5450
    },
    {
      "epoch": 1.944920873485987,
      "grad_norm": 0.7547641396522522,
      "learning_rate": 1.0555162659123056e-05,
      "loss": 0.3252,
      "step": 5500
    },
    {
      "epoch": 1.944920873485987,
      "eval_loss": 0.3196796178817749,
      "eval_runtime": 71.8019,
      "eval_samples_per_second": 157.531,
      "eval_steps_per_second": 19.693,
      "step": 5500
    },
    {
      "epoch": 1.962602776058704,
      "grad_norm": 0.7795464992523193,
      "learning_rate": 1.037835926449788e-05,
      "loss": 0.3313,
      "step": 5550
    },
    {
      "epoch": 1.9802846786314208,
      "grad_norm": 0.9726186990737915,
      "learning_rate": 1.0201555869872702e-05,
      "loss": 0.3294,
      "step": 5600
    },
    {
      "epoch": 1.9979665812041376,
      "grad_norm": 0.8259989023208618,
      "learning_rate": 1.0024752475247525e-05,
      "loss": 0.3278,
      "step": 5650
    },
    {
      "epoch": 2.0155600742639908,
      "grad_norm": 0.761432409286499,
      "learning_rate": 9.84794908062235e-06,
      "loss": 0.2623,
      "step": 5700
    },
    {
      "epoch": 2.033241976836708,
      "grad_norm": 1.249658226966858,
      "learning_rate": 9.671145685997172e-06,
      "loss": 0.2313,
      "step": 5750
    },
    {
      "epoch": 2.0509238794094244,
      "grad_norm": 0.7664350867271423,
      "learning_rate": 9.494342291371995e-06,
      "loss": 0.2407,
      "step": 5800
    },
    {
      "epoch": 2.068605781982141,
      "grad_norm": 0.8288639783859253,
      "learning_rate": 9.317538896746818e-06,
      "loss": 0.2402,
      "step": 5850
    },
    {
      "epoch": 2.086287684554858,
      "grad_norm": 0.7223705053329468,
      "learning_rate": 9.140735502121642e-06,
      "loss": 0.2486,
      "step": 5900
    },
    {
      "epoch": 2.1039695871275748,
      "grad_norm": 0.7995108366012573,
      "learning_rate": 8.963932107496465e-06,
      "loss": 0.2324,
      "step": 5950
    },
    {
      "epoch": 2.121651489700292,
      "grad_norm": 0.7269601225852966,
      "learning_rate": 8.787128712871288e-06,
      "loss": 0.2496,
      "step": 6000
    },
    {
      "epoch": 2.121651489700292,
      "eval_loss": 0.32701757550239563,
      "eval_runtime": 72.0783,
      "eval_samples_per_second": 156.927,
      "eval_steps_per_second": 19.618,
      "step": 6000
    },
    {
      "epoch": 2.1393333922730084,
      "grad_norm": 0.8106122016906738,
      "learning_rate": 8.61032531824611e-06,
      "loss": 0.2528,
      "step": 6050
    },
    {
      "epoch": 2.1570152948457255,
      "grad_norm": 1.0646028518676758,
      "learning_rate": 8.433521923620935e-06,
      "loss": 0.244,
      "step": 6100
    },
    {
      "epoch": 2.174697197418442,
      "grad_norm": 0.8001036047935486,
      "learning_rate": 8.256718528995758e-06,
      "loss": 0.2424,
      "step": 6150
    },
    {
      "epoch": 2.192379099991159,
      "grad_norm": 0.8043221831321716,
      "learning_rate": 8.07991513437058e-06,
      "loss": 0.2351,
      "step": 6200
    },
    {
      "epoch": 2.210061002563876,
      "grad_norm": 0.9015107750892639,
      "learning_rate": 7.903111739745404e-06,
      "loss": 0.2543,
      "step": 6250
    },
    {
      "epoch": 2.227742905136593,
      "grad_norm": 0.9620775580406189,
      "learning_rate": 7.726308345120226e-06,
      "loss": 0.2513,
      "step": 6300
    },
    {
      "epoch": 2.2454248077093095,
      "grad_norm": 0.9708914756774902,
      "learning_rate": 7.54950495049505e-06,
      "loss": 0.235,
      "step": 6350
    },
    {
      "epoch": 2.2631067102820266,
      "grad_norm": 0.9825096130371094,
      "learning_rate": 7.372701555869873e-06,
      "loss": 0.2378,
      "step": 6400
    },
    {
      "epoch": 2.280788612854743,
      "grad_norm": 0.9693079590797424,
      "learning_rate": 7.1958981612446955e-06,
      "loss": 0.2423,
      "step": 6450
    },
    {
      "epoch": 2.29847051542746,
      "grad_norm": 1.0243793725967407,
      "learning_rate": 7.019094766619519e-06,
      "loss": 0.2366,
      "step": 6500
    },
    {
      "epoch": 2.29847051542746,
      "eval_loss": 0.3257294297218323,
      "eval_runtime": 72.1373,
      "eval_samples_per_second": 156.798,
      "eval_steps_per_second": 19.602,
      "step": 6500
    },
    {
      "epoch": 2.316152418000177,
      "grad_norm": 0.7925121784210205,
      "learning_rate": 6.842291371994342e-06,
      "loss": 0.2318,
      "step": 6550
    },
    {
      "epoch": 2.3338343205728935,
      "grad_norm": 0.7528064846992493,
      "learning_rate": 6.665487977369166e-06,
      "loss": 0.2387,
      "step": 6600
    },
    {
      "epoch": 2.3515162231456106,
      "grad_norm": 0.9175788164138794,
      "learning_rate": 6.488684582743988e-06,
      "loss": 0.2456,
      "step": 6650
    },
    {
      "epoch": 2.369198125718327,
      "grad_norm": 0.8617270588874817,
      "learning_rate": 6.311881188118812e-06,
      "loss": 0.2468,
      "step": 6700
    },
    {
      "epoch": 2.3868800282910443,
      "grad_norm": 0.8195238709449768,
      "learning_rate": 6.135077793493635e-06,
      "loss": 0.2427,
      "step": 6750
    },
    {
      "epoch": 2.404561930863761,
      "grad_norm": 0.9339699149131775,
      "learning_rate": 5.9582743988684585e-06,
      "loss": 0.2451,
      "step": 6800
    },
    {
      "epoch": 2.422243833436478,
      "grad_norm": 0.8123636841773987,
      "learning_rate": 5.781471004243281e-06,
      "loss": 0.222,
      "step": 6850
    },
    {
      "epoch": 2.4399257360091946,
      "grad_norm": 0.7947497963905334,
      "learning_rate": 5.604667609618105e-06,
      "loss": 0.2529,
      "step": 6900
    },
    {
      "epoch": 2.4576076385819112,
      "grad_norm": 0.6375815272331238,
      "learning_rate": 5.427864214992928e-06,
      "loss": 0.225,
      "step": 6950
    },
    {
      "epoch": 2.4752895411546283,
      "grad_norm": 0.7930504679679871,
      "learning_rate": 5.251060820367751e-06,
      "loss": 0.245,
      "step": 7000
    },
    {
      "epoch": 2.4752895411546283,
      "eval_loss": 0.3240688741207123,
      "eval_runtime": 72.5007,
      "eval_samples_per_second": 156.012,
      "eval_steps_per_second": 19.503,
      "step": 7000
    },
    {
      "epoch": 2.492971443727345,
      "grad_norm": 0.8191395998001099,
      "learning_rate": 5.074257425742574e-06,
      "loss": 0.2197,
      "step": 7050
    },
    {
      "epoch": 2.510653346300062,
      "grad_norm": 0.8831937313079834,
      "learning_rate": 4.897454031117397e-06,
      "loss": 0.2327,
      "step": 7100
    },
    {
      "epoch": 2.5283352488727786,
      "grad_norm": 0.792192816734314,
      "learning_rate": 4.720650636492221e-06,
      "loss": 0.2371,
      "step": 7150
    },
    {
      "epoch": 2.5460171514454957,
      "grad_norm": 0.8394487500190735,
      "learning_rate": 4.5438472418670434e-06,
      "loss": 0.2315,
      "step": 7200
    },
    {
      "epoch": 2.5636990540182123,
      "grad_norm": 0.8268308639526367,
      "learning_rate": 4.367043847241867e-06,
      "loss": 0.2523,
      "step": 7250
    },
    {
      "epoch": 2.5813809565909294,
      "grad_norm": 0.6708340048789978,
      "learning_rate": 4.19024045261669e-06,
      "loss": 0.2395,
      "step": 7300
    },
    {
      "epoch": 2.599062859163646,
      "grad_norm": 0.9321007132530212,
      "learning_rate": 4.0134370579915135e-06,
      "loss": 0.2416,
      "step": 7350
    },
    {
      "epoch": 2.6167447617363626,
      "grad_norm": 0.9343872666358948,
      "learning_rate": 3.836633663366336e-06,
      "loss": 0.2342,
      "step": 7400
    },
    {
      "epoch": 2.6344266643090797,
      "grad_norm": 0.8309866786003113,
      "learning_rate": 3.6598302687411595e-06,
      "loss": 0.246,
      "step": 7450
    },
    {
      "epoch": 2.6521085668817967,
      "grad_norm": 0.7979034781455994,
      "learning_rate": 3.4830268741159828e-06,
      "loss": 0.2383,
      "step": 7500
    },
    {
      "epoch": 2.6521085668817967,
      "eval_loss": 0.3227849304676056,
      "eval_runtime": 71.8806,
      "eval_samples_per_second": 157.358,
      "eval_steps_per_second": 19.672,
      "step": 7500
    },
    {
      "epoch": 2.6697904694545134,
      "grad_norm": 1.162170171737671,
      "learning_rate": 3.306223479490806e-06,
      "loss": 0.2353,
      "step": 7550
    },
    {
      "epoch": 2.68747237202723,
      "grad_norm": 0.8300561308860779,
      "learning_rate": 3.129420084865629e-06,
      "loss": 0.2481,
      "step": 7600
    },
    {
      "epoch": 2.705154274599947,
      "grad_norm": 0.9003483653068542,
      "learning_rate": 2.9526166902404524e-06,
      "loss": 0.2473,
      "step": 7650
    },
    {
      "epoch": 2.7228361771726637,
      "grad_norm": 0.9103756546974182,
      "learning_rate": 2.7758132956152756e-06,
      "loss": 0.2439,
      "step": 7700
    },
    {
      "epoch": 2.7405180797453808,
      "grad_norm": 0.9386422038078308,
      "learning_rate": 2.599009900990099e-06,
      "loss": 0.2385,
      "step": 7750
    },
    {
      "epoch": 2.7581999823180974,
      "grad_norm": 1.133302927017212,
      "learning_rate": 2.422206506364922e-06,
      "loss": 0.2372,
      "step": 7800
    },
    {
      "epoch": 2.775881884890814,
      "grad_norm": 0.7921963334083557,
      "learning_rate": 2.2454031117397453e-06,
      "loss": 0.2466,
      "step": 7850
    },
    {
      "epoch": 2.793563787463531,
      "grad_norm": 0.5677230954170227,
      "learning_rate": 2.0685997171145685e-06,
      "loss": 0.2424,
      "step": 7900
    },
    {
      "epoch": 2.811245690036248,
      "grad_norm": 0.799206554889679,
      "learning_rate": 1.8917963224893917e-06,
      "loss": 0.2298,
      "step": 7950
    },
    {
      "epoch": 2.8289275926089648,
      "grad_norm": 0.6142916083335876,
      "learning_rate": 1.714992927864215e-06,
      "loss": 0.23,
      "step": 8000
    },
    {
      "epoch": 2.8289275926089648,
      "eval_loss": 0.3218078315258026,
      "eval_runtime": 72.2649,
      "eval_samples_per_second": 156.521,
      "eval_steps_per_second": 19.567,
      "step": 8000
    },
    {
      "epoch": 2.8466094951816814,
      "grad_norm": 0.8272172212600708,
      "learning_rate": 1.5381895332390382e-06,
      "loss": 0.2367,
      "step": 8050
    },
    {
      "epoch": 2.8642913977543984,
      "grad_norm": 0.8187441825866699,
      "learning_rate": 1.3613861386138614e-06,
      "loss": 0.2329,
      "step": 8100
    },
    {
      "epoch": 2.881973300327115,
      "grad_norm": 0.7779384851455688,
      "learning_rate": 1.1845827439886846e-06,
      "loss": 0.2426,
      "step": 8150
    },
    {
      "epoch": 2.899655202899832,
      "grad_norm": 1.1624253988265991,
      "learning_rate": 1.0077793493635079e-06,
      "loss": 0.2454,
      "step": 8200
    },
    {
      "epoch": 2.9173371054725488,
      "grad_norm": 0.8752664923667908,
      "learning_rate": 8.309759547383311e-07,
      "loss": 0.2412,
      "step": 8250
    },
    {
      "epoch": 2.935019008045266,
      "grad_norm": 0.7406672239303589,
      "learning_rate": 6.541725601131542e-07,
      "loss": 0.242,
      "step": 8300
    },
    {
      "epoch": 2.9527009106179825,
      "grad_norm": 0.685020923614502,
      "learning_rate": 4.773691654879774e-07,
      "loss": 0.2362,
      "step": 8350
    },
    {
      "epoch": 2.9703828131906995,
      "grad_norm": 0.810326337814331,
      "learning_rate": 3.005657708628006e-07,
      "loss": 0.24,
      "step": 8400
    },
    {
      "epoch": 2.988064715763416,
      "grad_norm": 0.7462199330329895,
      "learning_rate": 1.2376237623762375e-07,
      "loss": 0.2395,
      "step": 8450
    }
  ],
  "logging_steps": 50,
  "max_steps": 8484,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.620234340165222e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
